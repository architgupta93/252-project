
%----------------------------------------------------------------------------------------
%	COLCLUSION
%----------------------------------------------------------------------------------------

\label{sec:conclusion}
\par{Static versus Dynamic Branches: The figures \ref{fig:static-branches} and \ref{fig:dynamic-branches} demonstrate that the benchmarks we have
tested tend to have more share of Instrinsic branches in their Dynamic branch counts than their Static counterpart. The share of intrinsic branches rises the most for \textsl{lud}: from less than 50\% to above 95\%. \textsl{lud}'s LU Decomposition algorithm has a loop which executes all the intrinsic branches in successive iteration. Most of the extrinsic branches only execute once and are involved in initlziations or intermediate data movement and setup. Hence, we see a dramatic improvement in the share of intrinsic branches for \textsl{lud}. \textsl{backprop} and \textsl{bfs} also have a similar behaviour, perhaps largely due to their iterative nature even in a data-parallel GPU code. \textsl{b+trees}, however, sees a reduction of share of intrinsic branches. This is perhaps due to the repeated data-bound checks that it must do while pointer-chasing down the tree. Finally, \textsl{gaussian} has no intrinsic branches, a feature unique to it as most branches in its code are data-bound checks while performing scalar product. With the exception of \textsl{gaussian} (The Gaussian Elimination algorithm), it seems that a task which is iterative and has loops in its main Kernel code may have a higher share of intinsic branches to its dynamic branch count. This may suggest that most intrinsic branches are in the critical, repetitive body of the code which is a reasonable expectation.}

\par{Share of Computational Slots Inactive: The results for this metric \ref{fig:comp-slots-wasted} does not demonstrate a clear distinction between the static and dynamic branches. Although there is insufficient data to deny existence of any distinct behaviour between the two types, it seems almost certain that extrinsic branches seem to have a significant share in the Inactive slots. For instance, three of the five tested (\testsl{gaussian}, \textsl{lud} and \textsl{backprop}) have a larger share of inactivity due to their extrinsic branches. It is especially perplexing for \textsl{lud}, where although most dynamic branches are overwhelmingly intrinsic (\ref{fig:dynamic-branches}) they contribute to little or no contribution to Inactivity. Moreover, \textsl{bfs} wastes more than half of its slots available on inactive intrinsic branches. In any case, we think the data here is too small to discern a general trend, but maybe suffiecient to undertake further investigation on the extent of damage by extrinsic branches.
}

\par{Taken Fraction: The results of taken fraction (\ref{fig:taken-fraction} are also in-conclusive. This is the metric which clearly demonstrates that more data will be needed. 
	However, this gain in performance is one side of a trade off. Since GPUs were originally designed to perform graphics manipulations, which are inherently data parallel, the performance of similar applications on a GPU results in significantly better performance as compared to a CPU. The flip side of the trade off is the loss of generality. General purpose CPUs are equipped with accurate branch prediction, Out of Order (OoO) cores, multi-level caches etc. in order to extract the maximum possible amount of instruction level parallelism (ILP) and to mitigate the performance hit that might arise from complicated control flow or poor spatial locality of data in the programs. On a GPU operating on a similar power/energy budget, these resources are reallocated to provide several, but extremely simple (almost bare) pipelines. This is done, assuming that the programs that run on this machine will exhibit a staggering amount of data parallelism.
}

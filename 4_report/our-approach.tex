%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%	OUR APPROACH
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:our-approach}
\subsection{Tagging CUDA Benchmarks}
	In order to measure our metrics, we use selected benchmarks from the RODINIA benchmark suite \cite{rodinia-benchmark-suite}. This comprises of a large of set of data parallel applications written for a variety of parallel platforms including openMPI, openCL and CUDA. We use the CUDA implementations and simulated these benchmarks on GPGPU-SIM \cite{gpgpu-sim} in order to be able to easily instrument some of the architectural parameters required for our measurements.

	\subsubsection*{Framework}	% Discuss the use of PTX (Why not PTXPlus, justifying
					% the concept of a computational slot
	GPGPU-Sim runs in two different modes: simulating Parallel Thread eXecution (PTX) and PTXPlus. PTX is a pseudo-assembly
language used by Nvidia's CUDA Programming environment. Instead of being run directly on the machine, the driver recompiles the
PTX into the native SASS implementation before execution. 
PTXPlus is a pseudo-language specifically used to model the functioning of SASS ISA of the Nvidia GT200 series GPUs. PTXPlus extends
the regular PTX by augmenting it with addressing modes, new instructions and data-types. The extension is a one-to-one map of most of
 the instructions of the regular SASS. However, the extension is only useful for a very limited range GPUs from Nvidia. 
 
	We decided to use the PTX assembly code for our purposes:
	\begin{itemize}
	\item The PTX compiler is a standard pseudo-assembly code for all CUDA kernels. The machine readable SASS changes with
	the GPU family and may not be backward compatible. A PTX code, however, is embedded in the executable; a newer
	family of processors may do a Just-in-Time(JIT) compilation to produce a machine-compatible code. 
	\item Most of the hardware-specific optimizations such as rearrangements and predication of instructions are done on the 
	recompiled SASS code. Hence, the PTX can be thought of as a faithful reproduction of the high-level code in a lower-level
	assembly construct.
	\item The SASS translation of the High-level Control structures are very difficult to predict a priori. Since identifying
	branches at the High-Level control structures is the only way, it is very difficult to trace these constructs to the
	 machine code.
	\item The GPGPU-Sim does not simulate the execution of the SASS code directly. Moreover, its PTXPlus infrastructure is only
	compatible for a limited range of Nvidia GPU families. The PTXPlus also known to ignore certain SASS instructions, such as
	those that modify the SIMT Stack. 
	\end{itemize}
		
	The practical difficulties as well as the inefficiencies of simulating the SASS were the main reasons for adopting PTX. However,
	we are aware that PTX is not an accurate representation of the machine code. Its features are considerably high level and may be a serious problem in capturing low-level branch behaviour: it uses an arbitrarily large logical register set, and many individual instructions may be compounded into a single PTX operation. Hence, it is reasonable to expect significant difference in the behaviour of branches in a machine code.

	\subsubsection*{Assumptions about the compiler}
					% Put in the validation checks that were put in to
					% ensure that only the correctly tagged benchmarks are
					% evaluated
	The procedure to tag the branches according to their nature in the program involves forming a trace from High-Level control
	structures to branch instructions. This conversion generally occurs through several passes of optimizations by a compiler 
	and finally the linker. Hence, the foundation of our framework was to pass identification marks that are preserved across
	the compilation process. 
	
	We have used assembly-language labels as identification tokens. There are two kinds of labels for the two kinds of branches, and a branch inherits the nature of the label that immediately precedes it in program order. Once a label is paired to a branch, it is invalidated and is never used to identify another branch. We have modified the simulator so that a branch will not be accepted if it is not preceded my a valid label. In order to enforce the intended mapping of branches, we have developed the following assumptions to guarantee mapping correctness:
		
	\begin{itemize}
	\begin{figure}
		\lstinputlisting{for_template.cc}
		\caption{The template for a For-loop in C, a widely used HLC structure
			\label{fig:for_template}}
	\end{figure}
	\item The PTX code generated from the High-level Control structures (henceforth, HLC structures) preserve the order of the operations that appear in the distinct blocks within these HLC structures. As a corollary, any assembly-language label will also occur in the same order among its neighbouring instructions within a structure. During the extensive trials of this assumption, we discovered that the PTX code was not always a plain representation as we had expected. Several optimizations were done which were difficult to predict. Loop unrolling was the especially unpredictable as the error in the map depends on the extent of unrolling which is highly context-specific. We turned-off all compiler optimizations, and didn't observe any violations to our assumptions.

	\item Any HLC structure has a definite character of being extrinsic or intrinsic. The branches that they produce inherit their nature. In some cases, we may not be able to clearly define the label of a high-level structure but can do so for each of its constituent branches. Since any HLC structure can be expressed as a control-flow graph or a decision tree with nodes representing binary decisions, it can always be expressed as a sequence of intrinsic or extrinsic branches by the nature of its nodes.

	\item A given HLC structure has a definite pattern in which its constituent branch appears. Such a pattern will certainly be present in the assembly of the HLC structure, and will be a subset of any other branches that may be produced by the HLC structure. For instance, the two branches for the loop that appear immediately before and at the very end of the iteration body in \ref{fig:for_template} are compulsory. There may be additional branches too (such as, if the \textsl{<condition>} contains boolean expressions compounded by logical operations). This is because any HLC structure has a certain minimum representation as a decision tree, and its node there form the compulsory branches. A substitution of its nodes by any decision tree for a boolean expression does not remove these branches.

	\item Assuming that we have correctly identified the compulsory patterns of all major HLC structures, if the number of static branches equal the number of branch labels, then our mapping is correct.
 This assertion can be easily proved: our branch labels create a ordered partition of our program. If we have correctly identified compulsory patterns of all HLC structures in the code, then each partition will have at least one branch and the first such branch in the program order will be preceded by a correctly-matched branch label. Therefore, as the premise says that labels equal branches, there is exactly one branch (correctly matched) in each partition. Hence, the mapping is correct. 
\end{itemize}

\subsection{Modifications to GPGPU-SIM}
	\subsubsection*{Branch target buffers}
	\begin{figure*}
		\lstinputlisting[language={}]{backprop.log}
		\caption{Some of the fields in the branch target buffer implemented in GPGPU-SIM
			\label{fig:btb-example}}
	\end{figure*}
	\par{In order to accommodate some of the metrics that we wish to measure, we had to make a few changes to the existing GPGPU-SIM architecture. Besides measuring the performance impact of branch instructions (as mentioned in section \ref{sec:problem-description}), we are also interested in knowing if extrinsic and intrinsic branches have characteristically different behavior. In order to measure this, we implemented branch target buffers (BTB) in GPGPU-SIM. Each shader core has its own BTB. Any branch instruction that is executed at least once reserves an entry in its shader's BTB. Since the branch instructions (static count) are few in number and we are doing a software simulation, it is fairly easy to maintain a BTB which can grow dynamically in size (unlike a practical hardware implementation, which would have a fixed size). Figure \ref{btb-example} shows the BTB resulting from the execution of the ``backprop'' algorithm from RODINIA benchmark suite. The different columns of the BTB are described below}

\begin{itemize}
	\item PC -- Program counter for the branch instruction
	\item TYPE -- This field can take two values. 'ext', implying that the branch is an extrinsic branch and 'int', implying that the branch is an intrinsic branch 
	\item TARGET -- The program counter to which the branch instruction jumps
	\item INSTANCES -- Every thread that was active when the branch instruction was encountered by the warp add 1 to the instances field
	\item TAKEN -- Of the threads that were active when the branch instruction was encountered, `TAKEN' represents the fraction of threads that took the branch
	\item OCCUPANCY -- Occupancy gives the average number of threads that were active immediately after the branch instruction was executed.\footnote{The initial idea was to characterize the branch instructions based on this value as well. However, we have left that as a future prospect due to the lack of data}
	\item DYN COUNT -- It represents the total number of times some warp executed this particular branch instruction
\end{itemize}

	\subsubsection*{Thread status tables}
	Thread status tables are used to evaluate the performance metric described in section \ref{sec:problem-description}. For every warp instruction being currently executed, thread status tables keep track of status of each thread in the warp. A warp can be marked as active if it is active in the current cycle. Otherwise, it is marked ``INACTIVE EXTRINSIC'' or ``INACTIVE INTRINSIC'', depending on the last branch instruction that deactivated the thread. Every time a warp diverges, the current status of all the threads is stored in a stack (similar to the SIMT stack used for PDOM convergence in \cite{fung-micro}) and the new status is updated depending on the nature of the current branch. This can be best illustrated by an example. Let us consider the control flow graph shown in Figure \ref{fig:control-flow-graph}. We will discuss the update of thread status tables assuming that the branch at A (say an extrinsic branch) has been executed. Moreover, C is an intrinsic branch. The execution proceeds as shown in Figure \ref{fig:control-flow-execution}.

\begin{center}
\begin{tabular}{|c|c|c|}
		\hline
		PC	& Reconvergence	&	Thread	\\	
		  	&	PC	&	status	\\
		\hline
		C	&		G&		E A A A \\
		B	&		G&		A E E E \\
		\hline
\end{tabular}
	\captionof{table}{Thread status tables implementing a stack structure to keep track of thread status values as threads diverge and converge subsequently. The stack grows downwards (B represents the current top of stack and will be executed next)
		\label{table:thread-status-table-after-A}}
\end{center}

The thread status represents the status of threads when the respective basic block will be executed (A -- active, E -- deactivated by an extrinsic branch, I -- deactivated by an intrinsic branch). Basic block B will  executed first. Divergence at C leads to new entries being pushed into the stack, which gets updated to look like:

\begin{center}
\begin{tabular}{|c|c|c|}
		\hline
		PC	& Reconvergence	&	Thread	\\	
		  	&	PC	&	status	\\
		\hline
		B	&		G&		A E E E \\
		D	&		F&		E A A I \\
		E	&		F&		E I I A \\
		\hline
\end{tabular}
	\captionof{table}{Thread status tables describing the threads immediately after branch at C is executed.
		\label{table:thread-status-table-after-B}}
\end{center}

\par{One can readily see that the thread status table maintains the status of threads in a warp across the various divergence/convergence events. Every instruction reads it thread status from the stack when it has been executed and updates the counts of respective status values. These values are then aggregated over all warps and reported to measure the performance impact}
